Not using distributed mode
[03:22:03.455772] job dir: /content/drive/MyDrive/ITML/mae-rankme/mae
[03:22:03.456223] Namespace(batch_size=64,
epochs=10,
accum_iter=1,
model='mae_vit_base_patch16',
input_size=224,
mask_ratio=0.75,
norm_pix_loss=False,
weight_decay=0.05,
lr=None,
blr=0.001,
min_lr=0.0,
warmup_epochs=40,
data_path='./dataset/tiny-imagenet-200',
output_dir='./output_dir',
log_dir='./output_dir',
device='cuda',
seed=0,
resume='',
start_epoch=0,
num_workers=10,
pin_mem=True,
world_size=1,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
use_enc_repre=False,
distributed=False)
[03:30:46.426274] Dataset ImageFolder
    Number of datapoints: 100000
    Root location: ./dataset/tiny-imagenet-200/train
    StandardTransform
Transform: Compose(
               RandomResizedCrop(size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic, antialias=warn)
               RandomHorizontalFlip(p=0.5)
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           )
[03:30:46.427360] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7b9e87fc3820>
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[03:30:48.447715] Model = MaskedAutoencoderViT(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (decoder_embed): Linear(in_features=768, out_features=512, bias=True)
  (decoder_blocks): ModuleList(
    (0-7): 8 x Block(
      (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=512, out_features=1536, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=512, out_features=512, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (decoder_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
  (decoder_pred): Linear(in_features=512, out_features=768, bias=True)
)
[03:30:48.448804] base lr: 1.00e-03
[03:30:48.449469] actual lr: 2.50e-04
[03:30:48.449839] accumulate grad iterations: 1
[03:30:48.450229] effective batch size: 64
[03:30:48.452367] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00025
    maximize: False
    weight_decay: 0.0
Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.00025
    maximize: False
    weight_decay: 0.05
)
[03:30:48.453866] Start training for 10 epochs
[03:30:48.456517] log_dir: ./output_dir
[03:31:26.087191] Epoch: [0]  [   0/1562]  eta: 16:19:33  lr: 0.000000  loss: 2.3527 (2.3527)  time: 37.6268  data: 35.0153  max mem: 5840
[03:32:21.156433] Epoch: [0]  [  20/1562]  eta: 1:53:26  lr: 0.000000  loss: 2.2127 (2.2488)  time: 2.7534  data: 2.5823  max mem: 6707
[03:33:18.640224] Epoch: [0]  [  40/1562]  eta: 1:32:54  lr: 0.000000  loss: 2.2177 (2.2381)  time: 2.8740  data: 2.7066  max mem: 6707
[03:34:14.097645] Epoch: [0]  [  60/1562]  eta: 1:24:23  lr: 0.000000  loss: 2.1366 (2.2157)  time: 2.7727  data: 2.6028  max mem: 6707
[03:35:11.027863] Epoch: [0]  [  80/1562]  eta: 1:20:03  lr: 0.000000  loss: 2.0930 (2.1858)  time: 2.8464  data: 2.6897  max mem: 6707
[03:36:08.651311] Epoch: [0]  [ 100/1562]  eta: 1:17:14  lr: 0.000000  loss: 2.0074 (2.1527)  time: 2.8809  data: 2.7156  max mem: 6707
Error in sys.excepthook:
Traceback (most recent call last):
  File "/usr/lib/python3.10/linecache.py", line 72, in checkcache
    stat = os.stat(fullname)
KeyboardInterrupt
Original exception was:
Traceback (most recent call last):
  File "/content/drive/MyDrive/ITML/mae-rankme/mae/main_pretrain.py", line 245, in <module>
    main(args)
  File "/content/drive/MyDrive/ITML/mae-rankme/mae/main_pretrain.py", line 195, in main
    train_stats = train_one_epoch(
  File "/content/drive/MyDrive/ITML/mae-rankme/mae/engine_pretrain.py", line 72, in train_one_epoch
    for data_iter_step, (samples, _) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):
  File "/content/drive/MyDrive/ITML/mae-rankme/mae/util/misc.py", line 147, in log_every
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1284, in _get_data
    success, data = self._try_get_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.10/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/usr/lib/python3.10/threading.py", line 324, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt